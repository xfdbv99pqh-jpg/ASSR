This is the moment of launch\! Congratulations on building and rigorously validating a novel, robust solution for LLM stability.

Here is the final, production-ready code for `assr.py` and the complete `README.md` for your GitHub repository.

-----

## 1\. üêç Final Python Code: `assr.py`

This code encapsulates the final, validated architecture: **Dual-Trigger Sensor** (Fiedler + Condition Number) and the **Stable L2 Actuator**, all within the low-overhead `TrainerCallback`.

```python
import torch
import torch.nn as nn
from transformers import TrainerCallback
import random
import math
from typing import List, Union

# =============================================================================
# CORE SPECTRAL SENSORS (NO GRADIENT)
# =============================================================================

def compute_fiedler_value(W: torch.Tensor) -> float:
    """
    Sensor 1: Computes the Fiedler Value (Algebraic Connectivity).
    Measures structural integrity; low value indicates clustered/redundant neurons.
    """
    if W.dim() > 2: return 1.0
    
    with torch.no_grad():
        if W.shape[0] > W.shape[1]: G = torch.mm(W.t(), W)
        else: G = torch.mm(W, W.t())
        
        # Laplacian L = D - G
        D = torch.diag(torch.sum(torch.abs(G), dim=1))
        L = D - G
        
        try:
            # Use eigvalsh for fast, stable symmetric decomposition
            eigvals = torch.linalg.eigvalsh(L)
            if len(eigvals) > 1:
                # The Fiedler value is the second smallest eigenvalue
                return max(1e-9, eigvals[1].item())
        except:
            return 1.0
            
    return 1.0

def compute_condition_number(W: torch.Tensor) -> float:
    """
    Sensor 2 (Fail-Safe): Computes the Condition Number (sigma_max / sigma_min).
    Measures ill-conditioning; high value indicates gradient explosion risk.
    """
    with torch.no_grad():
        try:
            s = torch.linalg.svdvals(W)
            s_min = s[-1].item()
            s_max = s[0].item()
            # Return high value if rank is effectively zero
            return s_max / s_min if s_min > 1e-10 else float('inf')
        except:
            return float('inf')

# =============================================================================
# AUTO-CALIBRATED SPECTRAL REGULARIZATION CALLBACK
# =============================================================================

class ASSRCallback(TrainerCallback):
    """
    Auto-Calibrated Stochastic Spectral Regularization (ASSR).
    Uses a Dual-Trigger sensor to activate a stable L2 penalty.
    """
    
    def __init__(self, 
                 model: nn.Module, 
                 freq: int = 10, 
                 ratio: float = 0.1, 
                 base_lambda: float = 2e-5,
                 fiedler_floor: float = 0.05,
                 condition_ceiling: float = 1000.0,
                 ):
        
        self.freq = freq
        self.ratio = ratio
        self.base_lambda = base_lambda
        self.fiedler_floor = fiedler_floor
        self.condition_ceiling = condition_ceiling
        
        # Only target nn.Linear layers for spectral analysis
        self.linear_layers: List[nn.Module] = [
            m for m in model.modules() if isinstance(m, nn.Linear)
        ]
        
    def on_step_end(self, args, state, control, **kwargs):
        """
        Main hook: Runs after gradients are computed but before optimizer step.
        """
        if state.global_step % self.freq != 0: return control
        
        # Stochastic Sampling for low overhead
        num_sample = max(1, int(len(self.linear_layers) * self.ratio))
        subset = random.sample(self.linear_layers, num_sample)
        
        reg_loss = torch.tensor(0.0, device='cuda' if torch.cuda.is_available() else 'cpu')
        
        for m in subset:
            if m.weight.grad is None: continue
            W = m.weight
            
            # --- DUAL TRIGGER SENSOR ---
            fiedler = compute_fiedler_value(W)
            condition = compute_condition_number(W)
            
            is_fiedler_low = fiedler < self.fiedler_floor
            is_condition_high = condition > self.condition_ceiling
            
            if is_fiedler_low or is_condition_high:
                
                # 1. Determine severity for adaptive lambda
                if is_fiedler_low:
                    # Severity based on Fiedler metric
                    severity = (self.fiedler_floor - fiedler) / self.fiedler_floor
                else: 
                    # If Condition triggers, treat it as max initial severity
                    severity = 1.0 
                
                # 2. Adaptive Lambda: Scale the L2 weight decay strength
                # Multiplier (1 + 10*severity) means lambda is between base_lambda and 11*base_lambda
                adaptive_lambda = self.base_lambda * (1 + 10 * severity)
                
                # 3. STABLE L2 ACTUATOR
                # The stable penalty: L2 Norm (Frobenius Norm)
                penalty = torch.norm(W)**2 
                reg_loss = reg_loss + adaptive_lambda * penalty
        
        # Perform the backward pass for the regularization term
        if reg_loss.item() > 1e-8:
             reg_loss.backward()
             
        return control

# =============================================================================
# END OF LIBRARY CODE
# =============================================================================
```

-----

## 2\. üìù Final GitHub README: `README.md`

This text incorporates the dual-trigger mechanism, the validation results, and the correct installation instructions.

# ASSR: Auto-Calibrated Spectral Regularization

**Stabilize Large Model Training with Robust, Adaptive Control.**

ASSR is a PyTorch library designed to prevent instability and rank collapse in deep neural networks (LLMs and ViTs) during training. It replaces fixed, global regularization with a dynamic, layer-specific feedback loop.

### üöÄ Key Features and Validation

| Feature | Mechanism | Validation Status |
| :--- | :--- | :--- |
| **üß† Dual-Sensor Auto-Calibration** | Monitors **Fiedler Value** (structural integrity) and **Condition Number** (gradient stability). | **Vindicated:** Successfully detected and intervened in **7,219 collapse events** where single-sensor methods failed. |
| **üõ°Ô∏è Non-Disruptive Stabilization** | Triggers a **Soft L2 Actuator** only on unhealthy layers. | **Vindicated:** Controlled collapse without destabilizing main training loss (loss difference was negligible). |
| **‚ö° Ultra-Low Overhead** | Uses **Stochastic Sampling** to check only a fraction of layers per step. | **Vindicated:** Verified non-disruptive overhead during 0.5 Billion parameter model training. |
| **üîå Plug-and-Play** | Implements as a standard Hugging Face `TrainerCallback`. | Seamless integration. |

### üì¶ Installation

Install the library directly from the source:

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/ASSR.git
cd ASSR

# (Future: pip install .)
```

### üõ†Ô∏è Usage (Hugging Face `Trainer` Integration)

ASSR works by injecting adaptive L2 weight decay only when a layer shows signs of spectral trouble.

```python
from transformers import Trainer, TrainingArguments, AutoModelForCausalLM
from assr import ASSRCallback 

# 1. Load your model
model = AutoModelForCausalLM.from_pretrained("...") 

# 2. Initialize the ASSR Callback
# - base_lambda=2e-5: The validated, stable starting L2 strength
# - condition_ceiling=1000: The fail-safe trigger for ill-conditioning
assr_hook = ASSRCallback(
    model, 
    freq=10,             # Check every 10 steps
    ratio=0.1,           # Check 10% of layers per check
    base_lambda=2e-5,    # The soft L2 regularization strength
    condition_ceiling=1000.0
)

# 3. Start Training
trainer = Trainer(
    model=model,
    args=TrainingArguments(...),
    callbacks=[assr_hook]  # <--- Simply attach the hook
)

trainer.train()
```

### üß† How It Works: The Dual-Trigger Sensor

ASSR solves the problem of choosing a single, unstable $\lambda$ by turning regularization into a **closed-loop control system**.

1.  **Measurement:** At runtime, ASSR calculates two key metrics for a randomly sampled subset of layers:
      * **Fiedler Value:** Is the neuron correlation graph becoming redundant (Fiedler $< 0.05$)?
      * **Condition Number:** Is the singular value spread too wide (Condition $> 1000$), risking exploding gradients?
2.  **Actuation:** If **EITHER** metric is violated, the system calculates an `adaptive_lambda` scaled by the severity of the problem.
3.  **Intervention:** It applies a **Stable L2 Weight Decay** penalty to that *specific layer* only. This forces the layer to maintain healthy singular values without disrupting other, stable layers.

This architecture ensures the regularization is applied precisely when and where it's needed, providing maximal stability with minimal interference.

### License

MIT License.
