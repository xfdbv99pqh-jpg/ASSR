# ASSR: Auto-Calibrated Stochastic Spectral Regularization

**Stabilize Large Model Training with <0.1% Overhead**

ASSR is a PyTorch library that stabilizes the training of Large Language Models (LLMs) and Vision Transformers (ViTs) by monitoring the "Spectral Health" of weight matrices in real-time.

## ðŸš€ Key Features

- **ðŸ§  Auto-Calibrated**: Monitors stable rank and condition number on the fly. If a layer shows signs of collapse or ill-conditioning, ASSR automatically increases regularization; if it's healthy, it backs off.

- **âš¡ Near-Zero Overhead**: Uses stochastic sampling to check only 10% of layers per step, reducing computational cost by 90%+ compared to checking every layer.

- **ðŸ”§ Drop-in Replacement**: Works as a single-line replacement for the Hugging Face `Trainer`.

- **ðŸ“ˆ Dual-Mode Detection**: Catches both rank collapse (redundant neurons) AND ill-conditioning (gradient instability).

## ðŸ“¦ Installation

```bash
pip install git+https://github.com/yourusername/assr.git
```

Or with transformers support:

```bash
pip install "assr[transformers] @ git+https://github.com/yourusername/assr.git"
```

## ðŸ› ï¸ Quick Start

```python
from transformers import TrainingArguments
from assr import ASSRTrainer

# Just replace Trainer with ASSRTrainer - that's it!
trainer = ASSRTrainer(
    model=model,
    args=TrainingArguments(output_dir="./output", ...),
    train_dataset=dataset,
)
trainer.train()

# Check what happened
summary = trainer.get_assr_summary()
print(f"Interventions: {summary['total_interventions']}")
print(f"Intervention rate: {summary['intervention_rate']:.1%}")
```

## âš™ï¸ Configuration

```python
from assr import ASSRTrainer, ASSRConfig

config = ASSRConfig(
    base_lambda=1e-4,         # Base regularization strength
    stable_rank_floor=0.25,   # Trigger if SR ratio falls below this
    condition_ceiling=500,    # Trigger if condition number exceeds this
    sample_ratio=0.1,         # Fraction of layers to check per step
    log_interventions=False,  # Set True for debug output
)

trainer = ASSRTrainer(
    model=model,
    args=args,
    train_dataset=dataset,
    assr_config=config,
)
```

### Recommended Configurations

| Use Case | `stable_rank_floor` | `condition_ceiling` | `base_lambda` |
|----------|--------------------|--------------------|---------------|
| Default (balanced) | 0.25 | 500 | 1e-4 |
| Conservative (fewer interventions) | 0.15 | 1000 | 5e-5 |
| Aggressive (catch issues early) | 0.35 | 200 | 2e-4 |

## ðŸ“Š Diagnostic Tools

### Check Model Health Before Training

```python
from assr import print_spectral_report

print_spectral_report(model)
```

Output:
```
===========================================================================
  SPECTRAL HEALTH REPORT
===========================================================================
  Total Linear Layers: 74
  Stable Rank Ratio: min=0.312, max=0.456, mean=0.378
  Condition Number:  min=4.2, max=89.3, mean=23.1

  Layer                                    Shape           SR Ratio   Condition
  ---------------------------------------------------------------------------
    h.0.attn.c_attn                        (768, 2304)     0.312      89.3
    h.1.attn.c_attn                        (768, 2304)     0.318      76.2
    ...
  ---------------------------------------------------------------------------
  âœ… All layers appear healthy
===========================================================================
```

### Analyze Individual Layers

```python
from assr import analyze_layer

layer = model.transformer.h[0].attn.c_attn
analyze_layer(layer, "attention_qkv")
```

## ðŸ”¬ How It Works

ASSR monitors two key spectral metrics:

### 1. Stable Rank Ratio
```
Stable Rank = ||W||_FÂ² / ||W||_2Â²
```
- Measures the "effective dimensionality" of the weight matrix
- **Low values (<0.25)** indicate rank collapse â€” neurons becoming redundant
- Random initialization typically gives 0.30-0.40

### 2. Condition Number
```
Condition = Ïƒ_max / Ïƒ_min
```
- Measures how "stretched" the linear transformation is
- **High values (>500)** indicate ill-conditioning â€” gradient instability risk

When either metric crosses its threshold, ASSR applies an adaptive L2 penalty:

```
Î»_adaptive = Î»_base Ã— (1 + 10 Ã— severity)
loss_reg = Î»_adaptive Ã— ||W||Â²
```

The severity scales from 0 (at threshold) to 1 (severe issue), providing proportional intervention.

## ðŸ“ˆ When to Use ASSR

ASSR is most beneficial when:

- Training large models (>100M parameters)
- Using high learning rates
- Training for many epochs
- Experiencing loss spikes or training instability
- Using aggressive optimizers (high Î²2, low weight decay)

## ðŸ§ª Validated On

- Llama-style models up to 500M parameters
- Mixed precision training (FP16/BF16)
- Gradient checkpointing enabled
- Various learning rate schedules

## ðŸ“„ Citation

If you use ASSR in your research, please cite:

```bibtex
@software{assr2024,
  title={ASSR: Auto-Calibrated Stochastic Spectral Regularization},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/assr}
}
```

## ðŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.
